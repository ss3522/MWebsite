{
  "articles": [
    {
      "path": "about.html",
      "title": "Sangbeom Seo",
      "description": "I am from Daegu, South Korea. I like soccer and music and love to talk about them.",
      "author": [],
      "contents": "\r\n\r\n\r\n\r\n",
      "last_modified": "2021-12-10T15:46:27+09:00"
    },
    {
      "path": "index.html",
      "title": "Sangbeom Seo",
      "author": [],
      "contents": "\r\n\r\n          \r\n          \r\n          Sangbeom\r\n          \r\n          \r\n          Home\r\n          About\r\n          Resume\r\n          \r\n          \r\n          Project\r\n           \r\n          ▾\r\n          \r\n          \r\n          Machine Learning\r\n          \r\n          \r\n          ☰\r\n          \r\n          \r\n      \r\n        \r\n          \r\n            Sangbeom Seo\r\n          \r\n          \r\n            \r\n              \r\n            \r\n            \r\n              \r\n            \r\n          \r\n\r\n          \r\n            \r\n              \r\n                  \r\n                    \r\n                      LinkedIn\r\n                    \r\n                  \r\n                \r\n                                \r\n                  \r\n                    \r\n                      GitHub\r\n                    \r\n                  \r\n                \r\n                              \r\n          \r\n\r\n          \r\n            \r\n              \r\n                                \r\n                  \r\n                    LinkedIn\r\n                  \r\n                \r\n                                \r\n                  \r\n                    GitHub\r\n                  \r\n                \r\n                              \r\n            \r\n          \r\n        \r\n      \r\n    \r\n\r\n    \r\n    \r\n    ",
      "last_modified": "2021-12-10T15:46:28+09:00"
    },
    {
      "path": "Resume.html",
      "title": "Sangbeom Seo",
      "author": [],
      "contents": "\r\nEDUCATION\r\nMississippi State University, Starkville, MS\r\nCollege of Business - Bachelor of Business Administration (January 2015 - May 2020)\r\nRicard C. Adkerson School of Accountancy - Master of Professional Accounting\r\nCAREER\r\nREPUBLIC OF KOREA AIRFORCE\r\nEnlisted Soldier (September 2015 - September 2017)\r\nKOREAN STUDENT ASSOCIATION\r\nTreasurer (December 2019 - May 2021)\r\nPresident (August 2021)\r\nACADEMIC INTERESTS\r\nFinancial Accounting\r\nAudit\r\nAccounting Data Analytics\r\nRELATED SKILLS\r\nLearned Basic Codes of R, JAVA\r\nFluent in Microsoft Word, Powerpoint, Excel\r\nLanguage; English, Korean\r\nCONTACT\r\n662-312-6933\r\nss3522@msstate.edu\r\n\r\n\r\n\r\n",
      "last_modified": "2021-12-10T15:46:28+09:00"
    },
    {
      "path": "SVMandBootstrap.html",
      "title": "SVM and Bagging & RF",
      "description": "Support Vector Machine and Bagging and Random Forest Exercise \n",
      "author": [],
      "contents": "\r\n\r\nContents\r\nExercise 1 (Bootstrap)\r\n1. Redo the bootstrap analysis, but use 10 samples. Change times = 100 to times = 10. How does the population estimate for mean change?\r\n2. Redo the bootstrap analysis, but find the median. What is the difference in population estimate for the median vs mean?\r\n\r\nExercise 1 (SVM)\r\n1. Change the training to testing split size, for example change from a 60%:40% to a 75%:25%, and to a 50%:50%. Compare the results to the 60/40.\r\n2. Change the Kernel…use svmPoly for the method. method = “svmLinear”, to method = “svmPoly”, compare the linear results with the polynomial results.\r\n\r\n\r\nExercise 1 (Bootstrap)\r\n1. Redo the bootstrap analysis, but use 10 samples. Change times = 100 to times = 10. How does the population estimate for mean change?\r\n- The population estimate does not change after changing the number of samples.\r\n\r\n\r\nShow code\r\n\r\nlibrary(curl)\r\nload(curl(\"https://raw.githubusercontent.com/Professor-Hunt/ACC8143/main/data/tips.rda\"))\r\n\r\nset.seed(0)\r\nlibrary(rsample)\r\nlibrary(tidyverse)\r\n\r\n#perform bootstrapping with 2000 replications\r\nresample2 <- bootstraps(as.data.frame(tips$size), times = 10)\r\n\r\n#mean\r\nmean(resample2$splits[[1]]$data$`tips$size`)\r\n\r\n\r\n[1] 2.569672\r\n\r\nShow code\r\n\r\n#standard deviation\r\nsd(resample2$splits[[1]]$data$`tips$size`)\r\n\r\n\r\n[1] 0.9510998\r\n\r\n2. Redo the bootstrap analysis, but find the median. What is the difference in population estimate for the median vs mean?\r\n- Population estimate for median and mean is different. Median is 2 while mean is 2.569672.\r\n\r\n\r\nShow code\r\n\r\nresample1 <- bootstraps(as.data.frame(tips$size), times = 100)\r\nmedian(resample1$splits[[1]]$data$`tips$size`)\r\n\r\n\r\n[1] 2\r\n\r\nShow code\r\n\r\nmean(resample1$splits[[1]]$data$`tips$size`)\r\n\r\n\r\n[1] 2.569672\r\n\r\nExercise 1 (SVM)\r\n1. Change the training to testing split size, for example change from a 60%:40% to a 75%:25%, and to a 50%:50%. Compare the results to the 60/40.\r\n- Compared to the resuls to the 60:40, accuracy and kappa were bigger when testing size was 75:25 and 50:50. Also, they were biggest when the size of testing sample was 50%.\r\n\r\n\r\nShow code\r\n\r\nlibrary(caret)\r\nlibrary(tidyverse)\r\n#set the seed :)\r\nset.seed(1)\r\ntrainIndex <- createDataPartition(iris$Species, p = .75, list = FALSE, times = 1)\r\n\r\n#grab the data\r\nSVMTrain <- iris[ trainIndex,]\r\nSVMTest  <- iris[-trainIndex,]\r\n\r\niris_SVM <- train(\r\n  form = factor(Species) ~ .,\r\n  data = SVMTrain,\r\n  #here we add classProbs because we want probs\r\n  trControl = trainControl(method = \"cv\", number = 10,\r\n                           classProbs =  TRUE),\r\n  method = \"svmLinear\",\r\n  preProcess = c(\"center\", \"scale\"),\r\n  tuneLength = 10)\r\n\r\niris_SVM\r\n\r\n\r\nSupport Vector Machines with Linear Kernel \r\n\r\n114 samples\r\n  4 predictor\r\n  3 classes: 'setosa', 'versicolor', 'virginica' \r\n\r\nPre-processing: centered (4), scaled (4) \r\nResampling: Cross-Validated (10 fold) \r\nSummary of sample sizes: 102, 102, 103, 103, 104, 102, ... \r\nResampling results:\r\n\r\n  Accuracy   Kappa\r\n  0.9833333  0.975\r\n\r\nTuning parameter 'C' was held constant at a value of 1\r\n\r\n\r\n\r\nShow code\r\n\r\ntrainIndex50 <- createDataPartition(iris$Species, p = .5, list = FALSE, times = 1)\r\n\r\n#look at the first few\r\n#head(trainIndex)\r\n\r\n#grab the data\r\nSVMTrain50 <- iris[ trainIndex50,]\r\nSVMTest50  <- iris[-trainIndex50,]\r\n\r\n\r\niris_SVM50 <- train(\r\n  form = factor(Species) ~ .,\r\n  data = SVMTrain50,\r\n  #here we add classProbs because we want probs\r\n  trControl = trainControl(method = \"cv\", number = 10,\r\n                           classProbs =  TRUE),\r\n  method = \"svmLinear\",\r\n  preProcess = c(\"center\", \"scale\"),\r\n  tuneLength = 10)\r\n\r\niris_SVM50\r\n\r\n\r\nSupport Vector Machines with Linear Kernel \r\n\r\n75 samples\r\n 4 predictor\r\n 3 classes: 'setosa', 'versicolor', 'virginica' \r\n\r\nPre-processing: centered (4), scaled (4) \r\nResampling: Cross-Validated (10 fold) \r\nSummary of sample sizes: 69, 67, 68, 67, 69, 66, ... \r\nResampling results:\r\n\r\n  Accuracy   Kappa    \r\n  0.9440476  0.9147671\r\n\r\nTuning parameter 'C' was held constant at a value of 1\r\n\r\n2. Change the Kernel…use svmPoly for the method. method = “svmLinear”, to method = “svmPoly”, compare the linear results with the polynomial results.\r\n\r\n\r\nShow code\r\n\r\nset.seed(1)\r\n#get our samples\r\n#using the iris data\r\n#lets split the data 60/40\r\n\r\ntrainIndex22 <- createDataPartition(iris$Species, p = .6, list = FALSE, times = 1)\r\n\r\n#look at the first few\r\n#head(trainIndex)\r\n\r\n#grab the datas\r\nSVMTrain22 <- iris[ trainIndex22,]\r\nSVMTest22  <- iris[-trainIndex22,]\r\n\r\n\r\niris_SVM22 <- train(\r\n  form = factor(Species) ~ .,\r\n  data = SVMTrain22,\r\n  #here we add classProbs because we want probs\r\n  trControl = trainControl(method = \"cv\", number = 10,\r\n                           classProbs =  TRUE),\r\n  method = \"svmPoly\",\r\n  preProcess = c(\"center\", \"scale\"),\r\n  tuneLength = 10)\r\n\r\niris_SVM22\r\n\r\n\r\nSupport Vector Machines with Polynomial Kernel \r\n\r\n90 samples\r\n 4 predictor\r\n 3 classes: 'setosa', 'versicolor', 'virginica' \r\n\r\nPre-processing: centered (4), scaled (4) \r\nResampling: Cross-Validated (10 fold) \r\nSummary of sample sizes: 81, 81, 81, 81, 81, 81, ... \r\nResampling results across tuning parameters:\r\n\r\n  degree  scale  C       Accuracy   Kappa    \r\n  1       1e-03    0.25  0.9111111  0.8666667\r\n  1       1e-03    0.50  0.9111111  0.8666667\r\n  1       1e-03    1.00  0.9111111  0.8666667\r\n  1       1e-03    2.00  0.9111111  0.8666667\r\n  1       1e-03    4.00  0.9111111  0.8666667\r\n  1       1e-03    8.00  0.9111111  0.8666667\r\n  1       1e-03   16.00  0.9333333  0.9000000\r\n  1       1e-03   32.00  0.9333333  0.9000000\r\n  1       1e-03   64.00  0.9555556  0.9333333\r\n  1       1e-03  128.00  0.9777778  0.9666667\r\n  1       1e-02    0.25  0.9111111  0.8666667\r\n  1       1e-02    0.50  0.9111111  0.8666667\r\n  1       1e-02    1.00  0.9111111  0.8666667\r\n  1       1e-02    2.00  0.9444444  0.9166667\r\n  1       1e-02    4.00  0.9444444  0.9166667\r\n  1       1e-02    8.00  0.9444444  0.9166667\r\n  1       1e-02   16.00  0.9777778  0.9666667\r\n  1       1e-02   32.00  0.9666667  0.9500000\r\n  1       1e-02   64.00  0.9666667  0.9500000\r\n  1       1e-02  128.00  0.9666667  0.9500000\r\n  1       1e-01    0.25  0.9444444  0.9166667\r\n  1       1e-01    0.50  0.9444444  0.9166667\r\n  1       1e-01    1.00  0.9555556  0.9333333\r\n  1       1e-01    2.00  0.9555556  0.9333333\r\n  1       1e-01    4.00  0.9666667  0.9500000\r\n  1       1e-01    8.00  0.9666667  0.9500000\r\n  1       1e-01   16.00  0.9666667  0.9500000\r\n  1       1e-01   32.00  0.9666667  0.9500000\r\n  1       1e-01   64.00  0.9666667  0.9500000\r\n  1       1e-01  128.00  0.9666667  0.9500000\r\n  1       1e+00    0.25  0.9555556  0.9333333\r\n  1       1e+00    0.50  0.9666667  0.9500000\r\n  1       1e+00    1.00  0.9666667  0.9500000\r\n  1       1e+00    2.00  0.9666667  0.9500000\r\n  1       1e+00    4.00  0.9666667  0.9500000\r\n  1       1e+00    8.00  0.9666667  0.9500000\r\n  1       1e+00   16.00  0.9777778  0.9666667\r\n  1       1e+00   32.00  0.9777778  0.9666667\r\n  1       1e+00   64.00  0.9666667  0.9500000\r\n  1       1e+00  128.00  0.9666667  0.9500000\r\n  1       1e+01    0.25  0.9666667  0.9500000\r\n  1       1e+01    0.50  0.9666667  0.9500000\r\n  1       1e+01    1.00  0.9777778  0.9666667\r\n  1       1e+01    2.00  0.9666667  0.9500000\r\n  1       1e+01    4.00  0.9666667  0.9500000\r\n  1       1e+01    8.00  0.9777778  0.9666667\r\n  1       1e+01   16.00  0.9666667  0.9500000\r\n  1       1e+01   32.00  0.9888889  0.9833333\r\n  1       1e+01   64.00  0.9888889  0.9833333\r\n  1       1e+01  128.00  0.9777778  0.9666667\r\n  1       1e+02    0.25  0.9888889  0.9833333\r\n  1       1e+02    0.50  0.9888889  0.9833333\r\n  1       1e+02    1.00  0.9888889  0.9833333\r\n  1       1e+02    2.00  0.9777778  0.9666667\r\n  1       1e+02    4.00  0.9888889  0.9833333\r\n  1       1e+02    8.00  0.9666667  0.9500000\r\n  1       1e+02   16.00  0.9666667  0.9500000\r\n  1       1e+02   32.00  0.9777778  0.9666667\r\n  1       1e+02   64.00  0.9666667  0.9500000\r\n  1       1e+02  128.00  0.9666667  0.9500000\r\n  1       1e+03    0.25  0.9777778  0.9666667\r\n  1       1e+03    0.50  0.9888889  0.9833333\r\n  1       1e+03    1.00  0.9777778  0.9666667\r\n  1       1e+03    2.00  0.9777778  0.9666667\r\n  1       1e+03    4.00  0.9777778  0.9666667\r\n  1       1e+03    8.00  0.9888889  0.9833333\r\n  1       1e+03   16.00  0.9888889  0.9833333\r\n  1       1e+03   32.00  0.9666667  0.9500000\r\n  1       1e+03   64.00  0.9888889  0.9833333\r\n  1       1e+03  128.00  0.9777778  0.9666667\r\n  1       1e+04    0.25  0.9666667  0.9500000\r\n  1       1e+04    0.50  0.9666667  0.9500000\r\n  1       1e+04    1.00  0.9888889  0.9833333\r\n  1       1e+04    2.00  0.9777778  0.9666667\r\n  1       1e+04    4.00  0.9666667  0.9500000\r\n  1       1e+04    8.00  0.9888889  0.9833333\r\n  1       1e+04   16.00  0.9777778  0.9666667\r\n  1       1e+04   32.00  0.9666667  0.9500000\r\n  1       1e+04   64.00  0.9888889  0.9833333\r\n  1       1e+04  128.00  0.9888889  0.9833333\r\n  1       1e+05    0.25  0.9666667  0.9500000\r\n  1       1e+05    0.50  0.9888889  0.9833333\r\n  1       1e+05    1.00  0.9666667  0.9500000\r\n  1       1e+05    2.00  0.9888889  0.9833333\r\n  1       1e+05    4.00  0.9666667  0.9500000\r\n  1       1e+05    8.00  0.9888889  0.9833333\r\n  1       1e+05   16.00  0.9666667  0.9500000\r\n  1       1e+05   32.00  0.9888889  0.9833333\r\n  1       1e+05   64.00  0.9666667  0.9500000\r\n  1       1e+05  128.00  0.9666667  0.9500000\r\n  1       1e+06    0.25  0.9777778  0.9666667\r\n  1       1e+06    0.50  0.9777778  0.9666667\r\n  1       1e+06    1.00  0.9888889  0.9833333\r\n  1       1e+06    2.00  0.9888889  0.9833333\r\n  1       1e+06    4.00  0.9666667  0.9500000\r\n  1       1e+06    8.00  0.9888889  0.9833333\r\n  1       1e+06   16.00  0.9666667  0.9500000\r\n  1       1e+06   32.00  0.9888889  0.9833333\r\n  1       1e+06   64.00  0.9888889  0.9833333\r\n  1       1e+06  128.00  0.9888889  0.9833333\r\n  2       1e-03    0.25  0.9111111  0.8666667\r\n  2       1e-03    0.50  0.9111111  0.8666667\r\n  2       1e-03    1.00  0.9111111  0.8666667\r\n  2       1e-03    2.00  0.9111111  0.8666667\r\n  2       1e-03    4.00  0.9111111  0.8666667\r\n  2       1e-03    8.00  0.9333333  0.9000000\r\n  2       1e-03   16.00  0.9333333  0.9000000\r\n  2       1e-03   32.00  0.9555556  0.9333333\r\n  2       1e-03   64.00  0.9777778  0.9666667\r\n  2       1e-03  128.00  0.9666667  0.9500000\r\n  2       1e-02    0.25  0.9111111  0.8666667\r\n  2       1e-02    0.50  0.9111111  0.8666667\r\n  2       1e-02    1.00  0.9444444  0.9166667\r\n  2       1e-02    2.00  0.9222222  0.8833333\r\n  2       1e-02    4.00  0.9666667  0.9500000\r\n  2       1e-02    8.00  0.9777778  0.9666667\r\n  2       1e-02   16.00  0.9666667  0.9500000\r\n  2       1e-02   32.00  0.9666667  0.9500000\r\n  2       1e-02   64.00  0.9666667  0.9500000\r\n  2       1e-02  128.00  0.9666667  0.9500000\r\n  2       1e-01    0.25  0.9444444  0.9166667\r\n  2       1e-01    0.50  0.9666667  0.9500000\r\n  2       1e-01    1.00  0.9666667  0.9500000\r\n  2       1e-01    2.00  0.9666667  0.9500000\r\n  2       1e-01    4.00  0.9666667  0.9500000\r\n  2       1e-01    8.00  0.9666667  0.9500000\r\n  2       1e-01   16.00  0.9666667  0.9500000\r\n  2       1e-01   32.00  0.9666667  0.9500000\r\n  2       1e-01   64.00  0.9888889  0.9833333\r\n  2       1e-01  128.00  0.9888889  0.9833333\r\n  2       1e+00    0.25  0.9666667  0.9500000\r\n  2       1e+00    0.50  0.9666667  0.9500000\r\n  2       1e+00    1.00  0.9666667  0.9500000\r\n  2       1e+00    2.00  0.9666667  0.9500000\r\n  2       1e+00    4.00  0.9777778  0.9666667\r\n  2       1e+00    8.00  0.9666667  0.9500000\r\n  2       1e+00   16.00  0.9888889  0.9833333\r\n  2       1e+00   32.00  0.9777778  0.9666667\r\n  2       1e+00   64.00  0.9888889  0.9833333\r\n  2       1e+00  128.00  0.9888889  0.9833333\r\n  2       1e+01    0.25  0.9777778  0.9666667\r\n  2       1e+01    0.50  0.9666667  0.9500000\r\n  2       1e+01    1.00  0.9777778  0.9666667\r\n  2       1e+01    2.00  0.9666667  0.9500000\r\n  2       1e+01    4.00  0.9555556  0.9333333\r\n  2       1e+01    8.00  0.9555556  0.9333333\r\n  2       1e+01   16.00  0.9777778  0.9666667\r\n  2       1e+01   32.00  0.9777778  0.9666667\r\n  2       1e+01   64.00  0.9666667  0.9500000\r\n  2       1e+01  128.00  0.9666667  0.9500000\r\n  2       1e+02    0.25  0.9666667  0.9500000\r\n  2       1e+02    0.50  0.9777778  0.9666667\r\n  2       1e+02    1.00  0.9777778  0.9666667\r\n  2       1e+02    2.00  0.9666667  0.9500000\r\n  2       1e+02    4.00  0.9777778  0.9666667\r\n  2       1e+02    8.00  0.9777778  0.9666667\r\n  2       1e+02   16.00  0.9777778  0.9666667\r\n  2       1e+02   32.00  0.9777778  0.9666667\r\n  2       1e+02   64.00  0.9555556  0.9333333\r\n  2       1e+02  128.00  0.9666667  0.9500000\r\n  2       1e+03    0.25  0.9555556  0.9333333\r\n  2       1e+03    0.50  0.9555556  0.9333333\r\n  2       1e+03    1.00  0.9666667  0.9500000\r\n  2       1e+03    2.00  0.9555556  0.9333333\r\n  2       1e+03    4.00  0.9555556  0.9333333\r\n  2       1e+03    8.00  0.9555556  0.9333333\r\n  2       1e+03   16.00  0.9555556  0.9333333\r\n  2       1e+03   32.00  0.9555556  0.9333333\r\n  2       1e+03   64.00  0.9555556  0.9333333\r\n  2       1e+03  128.00  0.9555556  0.9333333\r\n  2       1e+04    0.25  0.8888889  0.8333333\r\n  2       1e+04    0.50  0.9111111  0.8666667\r\n  2       1e+04    1.00  0.9222222  0.8833333\r\n  2       1e+04    2.00  0.9222222  0.8833333\r\n  2       1e+04    4.00  0.9000000  0.8500000\r\n  2       1e+04    8.00  0.9111111  0.8666667\r\n  2       1e+04   16.00  0.9222222  0.8833333\r\n  2       1e+04   32.00  0.8888889  0.8333333\r\n  2       1e+04   64.00  0.9111111  0.8666667\r\n  2       1e+04  128.00  0.9000000  0.8500000\r\n  2       1e+05    0.25  0.8888889  0.8333333\r\n  2       1e+05    0.50  0.9000000  0.8500000\r\n  2       1e+05    1.00  0.9111111  0.8666667\r\n  2       1e+05    2.00  0.8666667  0.8000000\r\n  2       1e+05    4.00  0.9111111  0.8666667\r\n  2       1e+05    8.00  0.8666667  0.8000000\r\n  2       1e+05   16.00  0.8888889  0.8333333\r\n  2       1e+05   32.00  0.9000000  0.8500000\r\n  2       1e+05   64.00  0.9000000  0.8500000\r\n  2       1e+05  128.00  0.8777778  0.8166667\r\n  2       1e+06    0.25  0.9000000  0.8500000\r\n  2       1e+06    0.50  0.9000000  0.8500000\r\n  2       1e+06    1.00  0.8888889  0.8333333\r\n  2       1e+06    2.00  0.8666667  0.8000000\r\n  2       1e+06    4.00  0.8777778  0.8166667\r\n  2       1e+06    8.00  0.9000000  0.8500000\r\n  2       1e+06   16.00  0.8888889  0.8333333\r\n  2       1e+06   32.00  0.8777778  0.8166667\r\n  2       1e+06   64.00  0.9000000  0.8500000\r\n  2       1e+06  128.00  0.8888889  0.8333333\r\n  3       1e-03    0.25  0.9111111  0.8666667\r\n  3       1e-03    0.50  0.9111111  0.8666667\r\n  3       1e-03    1.00  0.9111111  0.8666667\r\n  3       1e-03    2.00  0.9111111  0.8666667\r\n  3       1e-03    4.00  0.9111111  0.8666667\r\n  3       1e-03    8.00  0.9444444  0.9166667\r\n  3       1e-03   16.00  0.9444444  0.9166667\r\n  3       1e-03   32.00  0.9666667  0.9500000\r\n  3       1e-03   64.00  0.9666667  0.9500000\r\n  3       1e-03  128.00  0.9666667  0.9500000\r\n  3       1e-02    0.25  0.9111111  0.8666667\r\n  3       1e-02    0.50  0.9333333  0.9000000\r\n  3       1e-02    1.00  0.9222222  0.8833333\r\n  3       1e-02    2.00  0.9444444  0.9166667\r\n  3       1e-02    4.00  0.9777778  0.9666667\r\n  3       1e-02    8.00  0.9666667  0.9500000\r\n  3       1e-02   16.00  0.9666667  0.9500000\r\n  3       1e-02   32.00  0.9666667  0.9500000\r\n  3       1e-02   64.00  0.9666667  0.9500000\r\n  3       1e-02  128.00  0.9666667  0.9500000\r\n  3       1e-01    0.25  0.9777778  0.9666667\r\n  3       1e-01    0.50  0.9666667  0.9500000\r\n  3       1e-01    1.00  0.9666667  0.9500000\r\n  3       1e-01    2.00  0.9666667  0.9500000\r\n  3       1e-01    4.00  0.9666667  0.9500000\r\n  3       1e-01    8.00  0.9666667  0.9500000\r\n  3       1e-01   16.00  0.9666667  0.9500000\r\n  3       1e-01   32.00  0.9777778  0.9666667\r\n  3       1e-01   64.00  0.9666667  0.9500000\r\n  3       1e-01  128.00  0.9777778  0.9666667\r\n  3       1e+00    0.25  0.9777778  0.9666667\r\n  3       1e+00    0.50  0.9777778  0.9666667\r\n  3       1e+00    1.00  0.9777778  0.9666667\r\n  3       1e+00    2.00  0.9777778  0.9666667\r\n  3       1e+00    4.00  0.9777778  0.9666667\r\n  3       1e+00    8.00  0.9777778  0.9666667\r\n  3       1e+00   16.00  0.9777778  0.9666667\r\n  3       1e+00   32.00  0.9777778  0.9666667\r\n  3       1e+00   64.00  0.9777778  0.9666667\r\n  3       1e+00  128.00  0.9777778  0.9666667\r\n  3       1e+01    0.25  0.9666667  0.9500000\r\n  3       1e+01    0.50  0.9666667  0.9500000\r\n  3       1e+01    1.00  0.9666667  0.9500000\r\n  3       1e+01    2.00  0.9777778  0.9666667\r\n  3       1e+01    4.00  0.9555556  0.9333333\r\n  3       1e+01    8.00  0.9666667  0.9500000\r\n  3       1e+01   16.00  0.9666667  0.9500000\r\n  3       1e+01   32.00  0.9666667  0.9500000\r\n  3       1e+01   64.00  0.9666667  0.9500000\r\n  3       1e+01  128.00  0.9555556  0.9333333\r\n  3       1e+02    0.25  0.9555556  0.9333333\r\n  3       1e+02    0.50  0.9666667  0.9500000\r\n  3       1e+02    1.00  0.9666667  0.9500000\r\n  3       1e+02    2.00  0.9666667  0.9500000\r\n  3       1e+02    4.00  0.9666667  0.9500000\r\n  3       1e+02    8.00  0.9666667  0.9500000\r\n  3       1e+02   16.00  0.9666667  0.9500000\r\n  3       1e+02   32.00  0.9666667  0.9500000\r\n  3       1e+02   64.00  0.9666667  0.9500000\r\n  3       1e+02  128.00  0.9555556  0.9333333\r\n  3       1e+03    0.25  0.9555556  0.9333333\r\n  3       1e+03    0.50  0.9666667  0.9500000\r\n  3       1e+03    1.00  0.9555556  0.9333333\r\n  3       1e+03    2.00  0.9555556  0.9333333\r\n  3       1e+03    4.00  0.9666667  0.9500000\r\n  3       1e+03    8.00  0.9666667  0.9500000\r\n  3       1e+03   16.00  0.9666667  0.9500000\r\n  3       1e+03   32.00  0.9666667  0.9500000\r\n  3       1e+03   64.00  0.9666667  0.9500000\r\n  3       1e+03  128.00  0.9555556  0.9333333\r\n  3       1e+04    0.25  0.9666667  0.9500000\r\n  3       1e+04    0.50  0.9666667  0.9500000\r\n  3       1e+04    1.00  0.9666667  0.9500000\r\n  3       1e+04    2.00  0.9666667  0.9500000\r\n  3       1e+04    4.00  0.9666667  0.9500000\r\n  3       1e+04    8.00  0.9666667  0.9500000\r\n  3       1e+04   16.00  0.9666667  0.9500000\r\n  3       1e+04   32.00  0.9666667  0.9500000\r\n  3       1e+04   64.00  0.9666667  0.9500000\r\n  3       1e+04  128.00  0.9666667  0.9500000\r\n  3       1e+05    0.25  0.9666667  0.9500000\r\n  3       1e+05    0.50  0.9555556  0.9333333\r\n  3       1e+05    1.00  0.9666667  0.9500000\r\n  3       1e+05    2.00  0.9666667  0.9500000\r\n  3       1e+05    4.00  0.9666667  0.9500000\r\n  3       1e+05    8.00  0.9555556  0.9333333\r\n  3       1e+05   16.00  0.9666667  0.9500000\r\n  3       1e+05   32.00  0.9666667  0.9500000\r\n  3       1e+05   64.00  0.9666667  0.9500000\r\n  3       1e+05  128.00  0.9666667  0.9500000\r\n  3       1e+06    0.25  0.9666667  0.9500000\r\n  3       1e+06    0.50  0.9555556  0.9333333\r\n  3       1e+06    1.00  0.9666667  0.9500000\r\n  3       1e+06    2.00  0.9666667  0.9500000\r\n  3       1e+06    4.00  0.9666667  0.9500000\r\n  3       1e+06    8.00  0.9555556  0.9333333\r\n  3       1e+06   16.00  0.9666667  0.9500000\r\n  3       1e+06   32.00  0.9666667  0.9500000\r\n  3       1e+06   64.00  0.9666667  0.9500000\r\n  3       1e+06  128.00  0.9666667  0.9500000\r\n\r\nAccuracy was used to select the optimal model using the\r\n largest value.\r\nThe final values used for the model were degree = 1, scale = 100\r\n and C = 0.25.\r\n\r\n\r\n\r\n\r\n",
      "last_modified": "2021-12-10T15:48:01+09:00"
    }
  ],
  "collections": ["posts/posts.json"]
}
